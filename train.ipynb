{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b879e035",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac90c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 27 15:41:32 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 517.00       Driver Version: 517.00       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   53C    P8     5W /  N/A |    136MiB /  4096MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      9940    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380bb35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finetuning\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f156c8",
   "metadata": {},
   "source": [
    "# Configure Finetune Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434be596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of implemented methods\n",
    "models   = ['t5-base', 'bart-base', 'gpt2']\n",
    "datasets = ['squad', 'wmt16_en_de', 'imdb']\n",
    "finetunes = ['full', 'lora', 'adapters']\n",
    "\n",
    "# Selecting index\n",
    "model, dataset, finetune = 2, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e25b7",
   "metadata": {},
   "source": [
    "## Saved Directory for Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8432614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = {\n",
    "    \"squad\": \"qa\",\n",
    "    \"wmt16_en_de\": \"translation\",\n",
    "    \"imdb\": \"textsentiment\"\n",
    "}\n",
    "\n",
    "model_path = f'models/ft-{models[model]}-{finetunes[finetune]}-{task[datasets[dataset]]}'\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb03690",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab12cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure training\n",
    "num_train_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0.02\n",
    "logging_steps = 1\n",
    "use_cpu = True\n",
    "\n",
    "# reduce if CUDA Out Of Memory\n",
    "train_batch_size = 1\n",
    "eval_batch_size = 1\n",
    "\n",
    "# turn into `False' for full training\n",
    "test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48019b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# setup manual for testing\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf3747",
   "metadata": {},
   "source": [
    "# Setup Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8d956",
   "metadata": {},
   "source": [
    "Wandb keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b4f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('api_key.json', 'r', encoding='utf-8') as file:\n",
    "    api_keys = json.load(file)\n",
    "\n",
    "WANDB_TOKEN, WANDB_API = api_keys['hf_token'], api_keys['hf_api']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f6aaf",
   "metadata": {},
   "source": [
    "Start trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trainers pipeline\n",
    "from modules.train.trainer import BaseTrainer\n",
    "\n",
    "\"\"\"\n",
    "Args:\n",
    "    device (torch.device): device used for finetuning.\n",
    "    model (str): name of the model.\n",
    "    dataset (str): name of the dataset.\n",
    "    finetune (str): name of the finetune strategy.\n",
    "\"\"\"\n",
    "\n",
    "# Configure\n",
    "trainer = BaseTrainer(\n",
    "    device=device,\n",
    "    model=models[model],\n",
    "    dataset=datasets[dataset],\n",
    "    finetune=finetunes[finetune],\n",
    "    train_batch_size=train_batch_size,\n",
    "    eval_batch_size=eval_batch_size,\n",
    "    test=test\n",
    ")\n",
    "\n",
    "# Set up api key\n",
    "trainer.set_wandb_api(wandb_token=WANDB_TOKEN, wandb_api=WANDB_API, project='phat-ft-nlp-test')\n",
    "\n",
    "# Start training loop\n",
    "trainer.run(\n",
    "    saved_model = model_path,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    learning_rate = learning_rate,\n",
    "    weight_decay = weight_decay,\n",
    "    use_cpu = use_cpu\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
