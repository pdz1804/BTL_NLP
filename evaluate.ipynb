{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfc6465",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dff9a6",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading finetuned model\n",
    "from modules.train.trainer import get_model_tokenizer\n",
    "\n",
    "# For testing performance\n",
    "from modules.prediction.predict import run_prediction\n",
    "\n",
    "# For loading test dataset\n",
    "from modules.data.hfdata import load_imdb, load_squad, load_wmt\n",
    "\n",
    "# For saving\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1eb4b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of implemented methods\n",
    "models   = ['t5-base', 'bart-base', 'prophetnet-large-uncased']\n",
    "datasets = ['squad', 'wmt16_en_de', 'imdb']\n",
    "finetunes = ['full', 'lora', 'adapters']\n",
    "\n",
    "# Selecting index\n",
    "model, dataset, finetune = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = {\n",
    "    \"squad\": \"qa\",\n",
    "    \"wmt16_en_de\": \"translation\",\n",
    "    \"imdb\": \"textsentiment\"\n",
    "}\n",
    "\n",
    "model_path = f'models/ft-{models[model]}-{finetunes[finetune]}-{task[datasets[dataset]]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397e96e",
   "metadata": {},
   "source": [
    "Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd04a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c8e5b",
   "metadata": {},
   "source": [
    "# Loading Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b47f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load finetuned model\n",
    "model, tokenizer = get_model_tokenizer(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9638305",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1a6e7",
   "metadata": {},
   "source": [
    "Getting data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get config from file\n",
    "with open('modules/data/config.json', 'r', encoding='utf-8') as file:\n",
    "    data_config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = None\n",
    "\n",
    "if dataset == 0:\n",
    "    _, test_dataset, _ = load_squad(test=False, data_config=data_config)\n",
    "    test_dataset = [\n",
    "        {\n",
    "            \"input\": \"question: \" + q + \" context: \" + c,\n",
    "            \"target\": a[\"text\"][0]\n",
    "        }\n",
    "        for q, c, a in zip(test_dataset[\"question\"], test_dataset[\"context\"], test_dataset[\"answers\"])\n",
    "    ]\n",
    "\n",
    "elif dataset == 1:\n",
    "    _, test_dataset, _ = load_wmt(test=False, data_config=data_config)\n",
    "    test_dataset = [\n",
    "        {\n",
    "            \"input\": d['translation']['en'],\n",
    "            \"target\": d['translation']['de']\n",
    "        }\n",
    "        for d in test_dataset\n",
    "    ]\n",
    "else: # dataset == 2\n",
    "    _, test_dataset, _ = load_imdb(test=False, data_config=data_config)\n",
    "    test_dataset = [\n",
    "        {\n",
    "            \"input\": d['test'],\n",
    "            \"target\": \"positive\" if d['label'] == 1 else \"negative\"\n",
    "        }\n",
    "        for d in test_dataset\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb7870",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'prediction/prediction-{models[model]}-{finetunes[finetune]}-{task[datasets[dataset]]}.json'\n",
    "\n",
    "success = run_prediction(model=model, tokenizer=tokenizer, test_dataset=test_dataset, output_dir=output_dir)\n",
    "\n",
    "if success:\n",
    "    print(f'Predicted values stored in {output_dir}')\n",
    "else:\n",
    "    print('Error in predicting.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
